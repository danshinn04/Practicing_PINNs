# -*- coding: utf-8 -*-
"""DanShinn_ENGR1050_Final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fDQNEED7-kno3XCoQYdSEdsJ-9GIBQpD
"""

from google.colab import drive
drive.mount('/content/drive')

"""V2: Added Physics loss function

V3: Added normalization and denormalization for prediction of data, added model architecture from running different sims

Edit 4(V4): Made the hagen poiseuille equation prediction better (!?)

Edit 5: Made Learning rate decay for PINNs

Part 1: Extrapolate Pressure guided by PINN loss function
"""

#Install the dataset from this link:
#https://figshare.com/articles/dataset/Figures_source_data_xlsx/13295915/1?file=25616711

#FOR FASTER SIMULATION, lower epoch and increase batch size :D currently with my crappy computer spyder simulation epoch 20 batch 32 takes 1 hr on colab slightly faster.
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from scipy.optimize import minimize
from tensorflow.keras.callbacks import LearningRateScheduler

def normalize_data(Pressure, Velocity_u, Velocity_v, Velocity_w):
    pressure_scaler = MinMaxScaler()
    normalized_pressure = pressure_scaler.fit_transform(Pressure)

    # Normalization above and below
    velocity_scaler = MinMaxScaler()
    normalized_velocity_u = velocity_scaler.fit_transform(Velocity_u)
    normalized_velocity_v = velocity_scaler.fit_transform(Velocity_v)
    normalized_velocity_w = velocity_scaler.fit_transform(Velocity_w)

    return normalized_pressure, normalized_velocity_u, normalized_velocity_v, normalized_velocity_w


def hagen_poiseuille_loss(y_true, y_pred, radius, length, flow_rate):
    viscosity = 0.001  # Fluid viscosity, relates with temperature for blood and it varies based on heparin blood thinner concentration because this was a surgery data. So it's not the usual amount.
    # HP equation of bloodflow
    pressure_drop = (8 * viscosity * length * flow_rate) / (np.pi * radius**4)

    # MSE computation but with a physics equation guiding so that the governing equation applies making learning faster.
    mse_loss = tf.keras.losses.mean_squared_error(y_true, y_pred - pressure_drop)

    return mse_loss

def fit_cylinder(coordinates):
    def residuals(params, coordinates):
        x0, y0, z0, a, b, c = params
        x, y, z = coordinates.T
        return np.sqrt((x - x0) ** 2 + (y - y0) ** 2 + (z - z0) ** 2) - np.sqrt(a ** 2 + b ** 2 + c ** 2)

    x0, y0, z0 = np.mean(coordinates, axis=0)
    initial_params = [x0, y0, z0, 1, 1, 1]
    result = minimize(lambda params: np.sum(residuals(params, coordinates) ** 2), initial_params)
    #Above is just assuming it is a linear regression cylinder, we need to approximate its radius so that we can apply physics equations to it.
    return result.x

def estimate_pipe_parameters(X, Y, Z, Pressure, Velocity_u, Velocity_v, Velocity_w):
    coordinates = np.hstack([X, Y, Z])
    direction, length = estimate_vessel_direction_and_length(X, Y, Z)

    # Calls on function above which calls on function below
    x0, y0, z0, a, b, c = fit_cylinder(coordinates)
    radius = np.sqrt(a ** 2 + b ** 2 + c ** 2)

    # Calculate the volumetric flow rate using the continuity equation (divergence-free)
    flow_rate = np.mean(Velocity_u * np.pi * (np.mean(Y) ** 2 + np.mean(Z) ** 2) +
                       Velocity_v * np.pi * (np.mean(X) ** 2 + np.mean(Z) ** 2) +
                       Velocity_w * np.pi * (np.mean(X) ** 2 + np.mean(Y) ** 2))

    return radius, length, flow_rate

def estimate_vessel_direction_and_length(X, Y, Z):
    coordinates = np.hstack([X, Y, Z])

    # Principal Componet Analysis
    pca = PCA(n_components=3)
    pca.fit(coordinates)

    # Estimate the dirN
    direction = pca.components_[0]

    # Estimate the length of the blood vessel using principal component analysis. I decided to just import instead of write it out.
    transformed_coordinates = pca.transform(coordinates)
    length = np.max(transformed_coordinates[:, 0]) - np.min(transformed_coordinates[:, 0])

    return direction, length

def denormalize_pressure(normalized_pressure, min_pressure, max_pressure):
    denormalized_pressure = normalized_pressure * (max_pressure - min_pressure) + min_pressure
    return denormalized_pressure

def maxmin(thingy):
    return np.max(thingy), np.min(thingy)

def create_model():
    input_shape = 6  #X, Y, Z coordinates and the three velocity components: u, v, w

    model = keras.Sequential([
        keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dense(1, activation = 'relu') #So that the final pressure is never negative because far away extrapolation might be negative but pressure can't be negative.
    ])

    return model


def exponential_decay_schedule(epoch, lr):
    initial_learning_rate = 0.01  # Initial learning rate
    decay_rate = 0.1  # Decay factor
    decay_step = 1
    new_lr = initial_learning_rate * (decay_rate ** (epoch // decay_step))
    return new_lr
    #Below should have called it way below so it's near main but this works same
lr_scheduler = LearningRateScheduler(exponential_decay_schedule)

def predict_pressure(model, x, y, z, velocity_u, velocity_v, velocity_w):
    # Normalize the velocity values
    velocity_scaler = MinMaxScaler()
    normalized_velocity_u = velocity_scaler.fit_transform(np.array([[velocity_u]]))
    normalized_velocity_v = velocity_scaler.fit_transform(np.array([[velocity_v]]))
    normalized_velocity_w = velocity_scaler.fit_transform(np.array([[velocity_w]]))

    # Initialize an input data array so it's clean
    input_data = np.array([[x, y, z, normalized_velocity_u[0, 0], normalized_velocity_v[0, 0], normalized_velocity_w[0, 0]]])

    # The thing
    normalized_pressure_prediction = model.predict(input_data, verbose=0)

    # Denormalize the predicted pressure because rn it's between 0 to 1
    max_pressure, min_pressure = maxmin(Pressure)
    pressure_prediction = denormalize_pressure(normalized_pressure_prediction, min_pressure, max_pressure)

    return pressure_prediction[0, 0]
def main():
    name = "/content/drive/My Drive/Preoperative-DL-velocity and pressure.csv"
    df = pd.read_csv(name, delimiter=',')
    data = df.to_numpy()
    # The thing
    global Velocity_u, Velocity_v, Velocity_w, Pressure
    X = data[:, 0].reshape(-1, 1)
    Y = data[:, 1].reshape(-1, 1)
    Z = data[:, 2].reshape(-1, 1)
    Velocity_u = data[:, 4].reshape(-1, 1)
    Velocity_v = data[:, 5].reshape(-1, 1)
    Velocity_w = data[:, 6].reshape(-1, 1)
    Pressure = data[:, 3].reshape(-1, 1)

    # Normalize pressure and velocity data
    normalized_pressure, normalized_velocity_u, normalized_velocity_v, normalized_velocity_w = normalize_data(Pressure, Velocity_u, Velocity_v, Velocity_w)

    # Estimate blood vessel parameters by using linear_regression like from class
    radius, length, flow_rate = estimate_pipe_parameters(X, Y, Z, normalized_pressure, normalized_velocity_u, normalized_velocity_v, normalized_velocity_w)

    input_data = np.hstack([X, Y, Z, normalized_velocity_u, normalized_velocity_v, normalized_velocity_w])
    X_train, X_test, y_train, y_test = train_test_split(input_data, normalized_pressure, test_size=0.1, random_state=42)
    model = create_model()

    # Calls on functions above, this is a physics informed loss function.
    def custom_loss(y_true, y_pred):
        return hagen_poiseuille_loss(y_true, y_pred, radius, length, flow_rate)

    # Compile the model with an optimizer and the custom loss function, if you look at lines 106 - 112, we see an exponential decay alpha function so that convergence does not overshoot.
    optimizer = keras.optimizers.Adam(learning_rate=0.01) #alpha value
    model.compile(loss=custom_loss, optimizer=optimizer)

    # Train the model
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=8, batch_size=32, callbacks=[lr_scheduler])
    test_loss = model.evaluate(X_test, y_test)
    print(f'Test loss: {test_loss}')


    # Plot the training and validation loss over time
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.legend()
    plt.show()

    return model

model = main()
# Predict pressure
x= -0.0107924482
y= -0.145006388
z= -0.0639464855
NU, NV, NW = (0.0511919856, 0.513168633, 0.542987466) #Not normalized so this answer is crappy but i forgot and running this takes hours so we have test function below

predicted_pressure = predict_pressure(model, x, y, z, NU, NV, NW)
print(f"Predicted pressure at point ({x}, {y}, {z}) with velocities ({NU}, {NV}, {NW}): {predicted_pressure}")

"""# New Section

Testing pressures
"""

x= -0.0107924482
y= -0.145006388
z= -0.0639464855
def normalize_that_velocity_boi(u,v,w, NU, NV, NW):
    this, that = maxmin(u)
    this2, that2 = maxmin(v)
    this3, that3 = maxmin(w)
    nu = (NU-that)/(this-that)
    nv = (NV-that2)/(this2-that2)
    nw = (NW-that3)/(this3-that3)
    return nu, nv, nw
a, b, c = (0.0511919856, 0.513168633, 0.542987466)
a,b,c = normalize_that_velocity_boi(Velocity_u,Velocity_v,Velocity_w,a,b,c)

predicted_pressure = predict_pressure(model, x, y, z, a, b, c)
print(predicted_pressure)

"""VELOCITY Prediction"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from scipy.optimize import minimize
from sklearn.decomposition import PCA

def normalize_data(Pressure, Velocity_u, Velocity_v, Velocity_w):
    pressure_scaler = MinMaxScaler()
    normalized_pressure = pressure_scaler.fit_transform(Pressure)

    # Normalize velocity data
    velocity_scaler = MinMaxScaler()
    normalized_velocity_u = velocity_scaler.fit_transform(Velocity_u)
    normalized_velocity_v = velocity_scaler.fit_transform(Velocity_v)
    normalized_velocity_w = velocity_scaler.fit_transform(Velocity_w)

    return normalized_pressure, normalized_velocity_u, normalized_velocity_v, normalized_velocity_w, pressure_scaler, velocity_scaler


def fit_cylinder(coordinates):
    def residuals(params, coordinates):
        x0, y0, z0, a, b, c = params
        x, y, z = coordinates.T
        return np.sqrt((x - x0) ** 2 + (y - y0) ** 2 + (z - z0) ** 2) - np.sqrt(a ** 2 + b ** 2 + c ** 2)

    x0, y0, z0 = np.mean(coordinates, axis=0)
    initial_params = [x0, y0, z0, 1, 1, 1]
    result = minimize(lambda params: np.sum(residuals(params, coordinates) ** 2), initial_params) #Stackoverflow

    return result.x

def estimate_pipe_parameters(X, Y, Z, Pressure, Velocity_u, Velocity_v, Velocity_w):
    # Same as f(x) above but we need it again and since structuring of data is slightly different I felt like writing it again although unnecessary it turned out.
    coordinates = np.hstack([X, Y, Z])
    direction, length = estimate_vessel_direction_and_length(X, Y, Z)
    x0, y0, z0, a, b, c = fit_cylinder(coordinates)
    radius = np.sqrt(a ** 2 + b ** 2 + c ** 2)
    flow_rate = np.mean(Velocity_u * np.pi * (np.mean(Y) ** 2 + np.mean(Z) ** 2) +
                       Velocity_v * np.pi * (np.mean(X) ** 2 + np.mean(Z) ** 2) +
                       Velocity_w * np.pi * (np.mean(X) ** 2 + np.mean(Y) ** 2))

    return radius, length, flow_rate

def estimate_vessel_direction_and_length(X, Y, Z):
#Same as prev f(x)
    coordinates = np.hstack([X, Y, Z])
    pca = PCA(n_components=3)
    pca.fit(coordinates)
    direction = pca.components_[0]
    transformed_coordinates = pca.transform(coordinates)
    length = np.max(transformed_coordinates[:, 0]) - np.min(transformed_coordinates[:, 0])

    return direction, length

def create_velocity_model():
    input_shape = 4  # X, Y, Z coordinates and pressure

    model = keras.Sequential([
        keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dense(3)  # Output will have 3 values: vu, vv, and vw, this time it can be negative
    ])

    return model

def predict_velocity(model, x, y, z, pressure, pressure_scaler, velocity_scaler):
    # Normalize the input pressure value
    normalized_pressure = pressure_scaler.transform(np.array([[pressure]]))
    input_data = np.array([[x, y, z, normalized_pressure[0, 0]]])
    normalized_velocity_prediction = model.predict(input_data, verbose=0) #verbose set to 0 so when i call on this function 400 times later on, it doesn't spam screen

    # Denormalize the normalized so we can see the real values
    denormalized_velocity_prediction = velocity_scaler.inverse_transform(normalized_velocity_prediction)

    return denormalized_velocity_prediction[0]

def main():
    name = "/content/drive/My Drive/Preoperative-DL-velocity and pressure.csv"
    df = pd.read_csv(name, delimiter=',')
    data = df.to_numpy()

    X = data[:, 0].reshape(-1, 1)
    Y = data[:, 1].reshape(-1, 1)
    Z = data[:, 2].reshape(-1, 1)
    Velocity_u = data[:, 4].reshape(-1, 1)
    Velocity_v = data[:, 5].reshape(-1, 1)
    Velocity_w = data[:, 6].reshape(-1, 1)
    Pressure = data[:, 3].reshape(-1, 1)
    # Up to now, we read from the df and normalize.

    normalized_pressure, normalized_velocity_u, normalized_velocity_v, normalized_velocity_w, pressure_scaler, velocity_scaler = normalize_data(Pressure, Velocity_u, Velocity_v, Velocity_w)

    # Formatting data cleanly for NN-ML
    input_data = np.hstack([X, Y, Z, normalized_pressure])
    output_data = np.hstack([normalized_velocity_u, normalized_velocity_v, normalized_velocity_w])

    # Splitting
    X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.1, random_state=42)
    # Unfortunately, I did not have enough time to complete the Immersed boundary navier stokes loss function because the complexity was too big so i wrote a MSE error function instead (I emailed you about this part)
    model = create_velocity_model()
    optimizer = keras.optimizers.Adam(learning_rate=0.01)
    model.compile(loss='mean_squared_error', optimizer=optimizer)

    # Could save the fitting param to a datafile but not yet
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=64)
    test_loss = model.evaluate(X_test, y_test)
    print(f'Test loss: {test_loss}')

    # Plot the training and validation loss over time
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.legend()
    plt.show()

    return model, pressure_scaler, velocity_scaler

vmodel, pressure_scaler, velocity_scaler = main()

# Use the trained model to predict velocity at a given point
x = -0.0107924482
y = -0.145006388
z = -0.0639464855
pressure = 0.358

predicted_velocity = predict_velocity(vmodel, x, y, z, pressure, pressure_scaler, velocity_scaler)
print(f"Predicted velocities at point ({x}, {y}, {z}) with pressure {pressure}: {predicted_velocity}")

"""Part 3: Run above CODES FIRST"""

import numpy as np
import matplotlib.pyplot as plt

def plot_velocity_heatmap(model, z, x_range, y_range, nx, ny, pressure_scaler, velocity_scaler):
    x_values = np.linspace(x_range[0], x_range[1], nx)
    y_values = np.linspace(y_range[0], y_range[1], ny)

    # Create a grid of points in the X-Y plane
    X_grid, Y_grid = np.meshgrid(x_values, y_values)

    # Calculate the predicted velocities at each point in the grid given avg pressure
    predicted_velocities = np.zeros((ny, nx, 3))
    for i in range(nx):
        for j in range(ny):
            x = X_grid[j, i]
            y = Y_grid[j, i]
            pressure = 0.358
            predicted_velocities[j, i] = predict_velocity(model, x, y, z, pressure, pressure_scaler, velocity_scaler)

    # Find the global minimum and maximum values of the predicted velocities
    vmin = np.min(predicted_velocities)
    vmax = np.max(predicted_velocities)

    # Draw Contour maps for analysis
    components = ['u', 'v', 'w']
    for i in range(3):
        plt.figure()
        plt.imshow(predicted_velocities[:, :, i], extent=[x_range[0], x_range[1], y_range[0], y_range[1]], origin='lower', aspect='auto', vmin=vmin, vmax=vmax)
        plt.colorbar(label=f'Velocity {components[i]} (m/s)')
        plt.contour(X_grid, Y_grid, predicted_velocities[:, :, i], colors='k', linewidths=0.5)
        plt.xlabel('X')
        plt.ylabel('Y')
        plt.title(f'Predicted Velocity {components[i]} at Z = {z}')
        plt.show()

import numpy as np
import matplotlib.pyplot as plt

########
#Basically the same as above but now we plot pressure map.


def plot_pressure_heatmap(pressure_model, z, x_range, y_range, nx, ny, pressure_scaler):
    x_values = np.linspace(x_range[0], x_range[1], nx)
    y_values = np.linspace(y_range[0], y_range[1], ny)

    # Create a grid of points in the X-Y plane
    X_grid, Y_grid = np.meshgrid(x_values, y_values)

    # Calculate the predicted pressure at each point in the grid
    predicted_pressures = np.zeros((ny, nx))
    for i in range(nx):
        for j in range(ny):
            x = X_grid[j, i]
            y = Y_grid[j, i]

            predicted_pressure = pressure_model.predict(np.array([[x, y, z, -0.1, -0.1, -0.1]]))
            predicted_pressures[j, i] = pressure_scaler.inverse_transform(predicted_pressure)

    # Plot heatmaps and contour lines for pressure
    plt.figure()
    plt.imshow(predicted_pressures, extent=[x_range[0], x_range[1], y_range[0], y_range[1]], origin='lower', aspect='auto')
    plt.colorbar(label='Pressure (Pa)')
    plt.contour(X_grid, Y_grid, predicted_pressures, colors='k', linewidths=0.5)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title(f'Predicted Pressure at Z = {z}')
    plt.show()

"""Part 4"""

z = -0.01
x_range = (-0.4, -0.2)
y_range = (-0.4, -0.2)
nx = 20
ny = 20
pressure_model = model

plot_velocity_heatmap(vmodel, z, x_range, y_range, nx, ny, pressure_scaler, velocity_scaler)

plot_pressure_heatmap(pressure_model, z, x_range, y_range, nx, ny, pressure_scaler)

import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

def create_sinusoidal_model():
    model = keras.Sequential([
        keras.layers.Dense(64, activation='relu', input_shape=(1,)),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(1)
    ])

    optimizer = keras.optimizers.Adam(learning_rate=0.001)
    model.compile(loss='mean_squared_error', optimizer=optimizer)

    return model

def plot_pressure_heatmap(pressure_model, z, x_range, y_range, nx, ny, sinusoidal_model):
    x_values = np.linspace(x_range[0], x_range[1], nx)
    y_values = np.linspace(y_range[0], y_range[1], ny)

    X_grid, Y_grid = np.meshgrid(x_values, y_values)

    predicted_pressures = np.zeros((ny, nx))
    for i in range(nx):
        for j in range(ny):
            x = X_grid[j, i]
            y = Y_grid[j, i]

            predicted_pressure = pressure_model.predict(np.array([[x, y, z, -0.1, -0.1, -0.1]]))

    plt.figure()
    plt.imshow(predicted_pressures, extent=[x_range[0], x_range[1], y_range[0], y_range[1]], origin='lower', aspect='auto')
    plt.colorbar(label='Pressure (Pa)')
    plt.contour(X_grid, Y_grid, predicted_pressures, colors='k', linewidths=0.5)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title(f'Predicted Pressure at Z = {z}')

    x_test = np.linspace(x_range[0], x_range[1], nx)
    y_pred = sinusoidal_model.predict(x_test).reshape(-1)
    plt.plot(x_test, y_pred, label='Sinusoidal Boundary')
    plt.legend()
    plt.show()


# Parameters for the heatmap
z = 0.5
x_range = [0, 10]
y_range = [0, 10]
nx = 15
ny = 15


# Create and train the sinusoidal boundary model
num_samples = 1000
x_data = np.linspace(0, 2 * np.pi, num_samples)
y_data = np.sin(x_data)
y_data += np.random.normal(0, 0.1, num_samples)

sinusoidal_model = create_sinusoidal_model()
history = sinusoidal_model.fit(x_data, y_data, epochs=100, batch_size=32, validation_split=0.2)

# Plot the pressure heatmap with the sinusoidal boundary
plot_pressure_heatmap(model, z, x_range, y_range, nx, ny, sinusoidal_model)

"""Part 5: Export"""

import numpy as np
import pandas as pd

def export_dataset(velocity_model, pressure_model, z_range, x_range, y_range, nx, ny, nz, pressure_scaler, velocity_scaler):
    x_values = np.linspace(x_range[0], x_range[1], nx)
    y_values = np.linspace(y_range[0], y_range[1], ny)
    z_values = np.linspace(z_range[0], z_range[1], nz)

    data = []

    for z in z_values:
        # Create a grid of points in the X-Y plane
        X_grid, Y_grid = np.meshgrid(x_values, y_values)

        # Initialize arrays for predicted velocities and pressure
        predicted_velocities = np.zeros((ny, nx, 3))
        predicted_pressures = np.zeros((ny, nx))

        # Calculate the predicted velocities and pressure at each point in the grid
        for i in range(nx):
            for j in range(ny):
                x = X_grid[j, i]
                y = Y_grid[j, i]
                pressure = 0.358
                predicted_velocities[j, i] = predict_velocity(velocity_model, x, y, z, pressure, pressure_scaler, velocity_scaler)
                predicted_pressure = pressure_model.predict(np.array([[x, y, z]]))
                predicted_pressures[j, i] = pressure_scaler.inverse_transform(predicted_pressure)

        # Flatten the arrays and append the data
        z_values_2d = np.full_like(predicted_pressures, z)
        data.extend(np.stack((z_values_2d.flatten(), X_grid.flatten(), Y_grid.flatten(),
                              predicted_velocities[:, :, 0].flatten(), predicted_velocities[:, :, 1].flatten(),
                              predicted_velocities[:, :, 2].flatten(), predicted_pressures.flatten()), axis=1))

    # Create a DataFrame
    columns = ['Z', 'X', 'Y', 'pred_vu', 'pred_vv', 'pred_vw', 'pred_pressure']
    df = pd.DataFrame(data, columns=columns)

    # Save the DataFrame to a CSV file
    df.to_csv('z_variance_PINNS_NSE_Interpolation.csv', index=False)
!cp z_variance_PINNS_NSE_Interpolation.csv "drive/My Drive/"